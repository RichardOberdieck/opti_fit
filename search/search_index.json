{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Optimal cutoff selection for string matching algorithms","text":"<p>At Banking Circle, we use a library designed to identify whether a given name is matching, with some variation, a (black)list of names. To achieve this, this library runs several algorithms such as regex matching, computing the fuzzy ratio and more. Most of these algorithms come with the notion of a <code>score</code>, and a hit is identified when the <code>score</code> is above a user-defined <code>cutoff</code>. Since false negatives (it should have been a hit, but is not detected) are unacceptable, the <code>cutoff</code>s have been set in such a way that we end up with a high percentage of false positives.</p> <p>The purpose of this body of work is to investigate how to reduce the false-positive rate without removing true positives. Specifically, we investigate the following \"simple\" questions:</p> <ul> <li>What is the optimal cutoff to minimize the amount of false positive hits?</li> <li>What is the optimal cutoff to minimize the amount of false positive payments?</li> </ul> <p>The results can be found in the Simple Model section.</p> <p>Based on these models, we investigated how much better of a reduction we can achieve by:</p> <ul> <li>Combining the scores from multiple algorithms together to achieve a better reduction of false positives, see the Algorithm Combination section.</li> <li>Allowing for the removal of some true positive hits or payments, see the Relax True Positive Requirement section.</li> </ul> <p>As we were provided a free evaluation license by Gurobi Optimization for a portion of this work, we also were interested in the impact of using a commerical versus an open-source solver in terms of runtime, stability and results. This analysis can be found in the Solver Comparison section.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>The code uses hatch as a project manager, with the <code>pyproject.toml</code> file for configuration. There are four command-line scripts that are defined to run the analysis:</p> <ul> <li><code>hatch run simple</code>: Solves the simple hit, payment or combined models, see the Simple Model section.</li> <li><code>hatch run relaxed</code>: Solves the relaxed hit or payment model, see the Relax True Positive Requirement section.</li> <li><code>hatch run combination</code>: Solve the algorithm combination model, see the Algorithm Combination section.</li> <li><code>hatch run compare</code>: Compares the different solvers, see the Solver Comparison section.</li> </ul> <p>To get started, install <code>hatch</code> and run one of the commands, e.g.:</p> <pre><code>hatch run simple\n</code></pre> <p>This will execute the script that picks a simple model, a dataset and solves it with the default settings. If you would like to specify the details, you can pass them as arguments, e.g.:</p> <pre><code>hatch run simple --model_name='simple_hit' --full_dataset=False --to_file=True\n</code></pre> <p>For more information, please check the help:</p> <pre><code>hatch run simple --help\n</code></pre>"},{"location":"#reproducibility","title":"Reproducibility","text":"<p>To run all the analysis as it is reported here, you simply need to execute the <code>runs.sh</code> script.</p> <p>Note that this may be very time consuming and require 32GB or more of RAM, depending on the dataset that is being solved. In addition, as you will see in the Solver Comparison section, running the full dataset without Gurobi is virtually impossible.</p> <p>All the versions of packages used are pinned to make it easier to reproduce the results. However, this is not the case for the CBC solver, which is downloaded by cloning the corresponding Github repository. This is an in-built design choice by the modeling framework <code>python-mip</code> that we used. </p> <p>Also note that it was necessary to pin a specific commit of <code>python-mip</code> since at the time of this writing the latest release (1.15.0) did not support the HiGHS solver, whereas the code was already available on the master branch.</p> <p>Finally, the data for all runs is stored in json files in the <code>results</code> folder of this repository. With it, you can recreate the configuration used for each run, as well as the performance and cutoffs achieved.</p>"},{"location":"algorithm-combination/","title":"Algorithm Combination","text":"<pre><code>hatch run combination --model_type='hit'\nhatch run combination --model_type='payment'\nhatch run combination --model_type='combined'\n</code></pre> <p>Having investigated the results from running the simple models, we were curious whether it would be beneficial to combine the scores of two algorithms together in order to gain an additional degree of freedom that can be used to remove false positives. We chose the following approach:</p> <ul> <li>Iterate over all possible combinations (15 in total) of algorithm pairs <code>(A,B)</code></li> <li>Choose 3 different weights <code>w</code> (0.1, 0.25, 0.4) to combine the score algorithm <code>A</code> with the score of algorithm <code>B</code>:</li> </ul> \\[ s_{(A,B)} = wA + (1-w)B \\] <ul> <li>For each combination <code>(A,B,w)</code>, calculate the resulting scores, add them to the dataset and run the simple model (either hit or payment). This results in a false positive removal percentage.</li> <li>Return the best percentage, and write the results from all runs (5*15=75 in total) to a json file.</li> </ul>"},{"location":"algorithm-combination/#why-only-2-algorithms","title":"Why only 2 algorithms?","text":"<p>We could have analyzed what would happen if we combined 3 or even more algorithms, but then it becomes much harder to explain to a regulator who audits the sanction screening program. We still may do this analysis in the future, but it was not the focus of the first approach.</p>"},{"location":"algorithm-combination/#implementation","title":"Implementation","text":""},{"location":"definitions/","title":"Definitions","text":"<p>In the code and the documentation, several terms are used that may require a deeper explanation:</p>"},{"location":"definitions/#sanctions","title":"Sanctions","text":"<p>A sanctioned entity is an entity such as a person, corporation, ship or country which is listed on a sanctions list. These lists are issued by goverments (e.g. the American, British or German), state unions (such as the European Union) or even by the United Nations. If an entity is on a list, a bank operating in the jurisdiction of the government to whom the list belong has a legal requirement to ensure that this entity cannot receive or send any funds. If a financial institution fails to have adequate controls in place, they can be fined. In 2023 alone, the U.S. sanctions enforcement issued fines worth $1.5bn.</p> <p>For a visual representation, this map shows the sanctions currently in place in the European Union.</p> <p>Note</p> <p>For ease of reading, we refer to a single \"sanctions list\". However, in reality, there are dozens of lists that a bank has to consider. They are, however, merged into a single list whenever possible.</p>"},{"location":"definitions/#payments-and-hits","title":"Payments and hits","text":"<p>A payment is a transaction where money is sent from a sender to a receiver. Legally, every payment needs to be screened for sanction violations. Each payment has a sender, a receiver, and maybe other components such as remitter information and addresses. Each of these components is screened against the sanctions list. This can result in one or more hits against names on the sanctions list. Therefore, in the context of sanction screening, we have the following structure:</p> <ul> <li>Payment 1<ul> <li>Hit 1</li> <li>Hit 2</li> <li>Hit 3</li> </ul> </li> <li>Payment 2<ul> <li>Hit 4</li> </ul> </li> <li>Payment 3<ul> <li>Hit 5</li> <li>Hit 6</li> </ul> </li> </ul> <p>Each of the hits is assessed by an analyst whether they are true/false positives. If a payment has at least one true positive, it is escalated and sent to the Financial Intelligence Unit (FIU) of the respective jurisdiction. If all hits in a payment are deemed false positives, the payment is released.</p> <p>Therefore, considering the example from above, we may have the following situation:</p> <ul> <li>Payment 1 - True positive<ul> <li>Hit 1 - True positive</li> <li>Hit 2 - False positive</li> <li>Hit 3 - True positive</li> </ul> </li> <li>Payment 2 - True positive<ul> <li>Hit 4 - True positive</li> </ul> </li> <li>Payment 3 - False positive<ul> <li>Hit 5 - False positive</li> <li>Hit 6 - False positive</li> </ul> </li> </ul> <p>\"Pythonically\", we can write that a payment <code>p</code> is a hit if:</p> <pre><code>any(h.is_hit_true_hit for h in H(p))\n</code></pre> <p>where <code>H(p)</code> is the set of all hits that are assigned to payment <code>p</code>.</p>"},{"location":"definitions/#algorithms","title":"Algorithms","text":"<p>Since it is impossible to manually review millions of payments a day, algorithms are used to perform the initial screening of the payments. Since the task at hand is essentially string matching, we chose to use the following algorithms:</p> <ul> <li>Regex match: Checks whether the name matches a regular expression variation of the blacklist.</li> <li>Jaro Winkler: Computes the Jaro Winkler distance between the name and corresponding blacklist name.</li> <li>Fuzz (Partial/Token Sort/Partial Token Sort) Ratio: This Stack Overflow post describes the algorithm in sufficient detail, so please refer there and the referenced links.</li> </ul> <p>These algorithms all work similarly in that they calculate a score. Based on experimentation, we have set a (conservative) cutoff (or threshold) for each of these algorithms. If the score exceeds the threshold, it is deemed a hit. \"Pythonically\" again, this means that a screening <code>h</code> is a considered a hit if:</p> <pre><code>any(h.score[a] &gt;= cutoff[a] for a in algorithms)\n</code></pre> <p>where <code>algorithms</code> is the set of all algorithms applied.</p> <p>Note</p> <p>There are also a couple of other algorithms, but they are not relevant for the analysis performed in this body of work. Also, note that there are a lot more compoenents that create a sanction screening tool than the string matching, although the string matching is a core component.</p>"},{"location":"future-ideas/","title":"Future ideas","text":"<p>While the current body of works does investigate a lot of nuances with regards to this problem, there are a few avenues that may be worth investigating at a later date:</p>"},{"location":"future-ideas/#using-the-number-of-hits","title":"Using the number of hits","text":"<p>As discussed in the Dataset section, there is a difference in the average number of hits. It is possible that some improvements can be gained by some sophisticated statistical analysis, although the path towards that is not clear.</p>"},{"location":"relax-the-true-positive-requirement/","title":"Relax the true positive requirement","text":"<pre><code>hatch run relaxed --model_type='hit'\n</code></pre> <pre><code>hatch run relaxed --model_type='payment'\n</code></pre> <p>What is the \"cost\", mathematically speaking, of enforcing that all true positives should be a hit? And how would that change if we were to relax this constraint?</p> <p>To analyze this, we only need to take the model from the Simple Model section and replace the true positive constraint:</p> \\[ z_h = 1 \\] <p>with</p> \\[ \\sum_{h\\in TP} z_h \\geq \\beta |TP| \\] <p>where:</p> <ul> <li>\\(\\beta \\in [0,1]\\) is the fraction of the true positive hits that should be a hit</li> <li>\\(|\\cdot |\\) is the cardinality of a set, i.e. \\(|TP|\\) refers to how many true positives there are</li> </ul> <p>Note</p> <p>It is trivial to extend to the case where payments are considered instead of hits.</p>"},{"location":"relax-the-true-positive-requirement/#implementation","title":"Implementation","text":""},{"location":"relax-the-true-positive-requirement/#opti_fit.models.relaxed_model.solve_relaxed_hit_model","title":"<code>solve_relaxed_hit_model(df, solver_name='CBC', slack=0.99)</code>","text":"<p>This mdoel allows for a fraction of the true positive hits to be violated.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Data with the scores etc.</p> required <code>solver_name</code> <code>str</code> <p>Name of the solver to used</p> <code>'CBC'</code> <code>slack</code> <code>float</code> <p>Fraction of true positives to keep</p> <code>0.99</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The optimal cutoffs</p> Source code in <code>opti_fit/models/relaxed_model.py</code> <pre><code>def solve_relaxed_hit_model(df: pd.DataFrame, solver_name: str = \"CBC\", slack: float = 0.99) -&gt; dict[str, float]:\n    \"\"\"This mdoel allows for a fraction of the true positive hits to be violated.\n\n    Args:\n        df (pd.DataFrame): Data with the scores etc.\n        solver_name (str): Name of the solver to used\n        slack (float): Fraction of true positives to keep\n\n    Returns:\n        The optimal cutoffs\n    \"\"\"\n    model = Model(solver_name=solver_name)\n\n    x, y, z = define_hit_variables(model, df, ALGORITHMS)\n\n    # Add constraints\n    objective = []\n    true_positive_constraint = []\n    for hit_id, scores in df.iterrows():\n        if scores[\"is_hit_true_hit\"]:\n            true_positive_constraint.append(z[hit_id])\n        else:\n            objective.append(z[hit_id])\n\n        model = define_cutoff_constraints(model, scores, x, y, z, ALGORITHMS, hit_id)\n\n    # Add true positive relaxed constraint\n    model += xsum(true_positive_constraint) &gt;= slack * len(true_positive_constraint)\n\n    # Add objective\n    model.objective = minimize(xsum(objective))\n    cutoffs = solve(model, DEFAULT_SEED, x)\n\n    return cutoffs\n</code></pre>"},{"location":"relax-the-true-positive-requirement/#opti_fit.models.relaxed_model.solve_relaxed_payment_model","title":"<code>solve_relaxed_payment_model(df, solver_name='CBC', slack=0.99)</code>","text":"<p>This mdoel allows for a fraction of the true positive payments to be violated.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Data with the scores etc.</p> required <code>solver_name</code> <code>str</code> <p>Name of the solver to use</p> <code>'CBC'</code> <code>slack</code> <code>float</code> <p>Fraction of true positives to keep</p> <code>0.99</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The optimal cutoffs</p> Source code in <code>opti_fit/models/relaxed_model.py</code> <pre><code>def solve_relaxed_payment_model(df: pd.DataFrame, solver_name: str = \"CBC\", slack: float = 0.99) -&gt; dict[str, float]:\n    \"\"\"This mdoel allows for a fraction of the true positive payments to be violated.\n\n    Args:\n        df (pd.DataFrame): Data with the scores etc.\n        solver_name (str): Name of the solver to use\n        slack (float): Fraction of true positives to keep\n\n    Returns:\n        The optimal cutoffs\n    \"\"\"\n    payment_df = df.groupby(\"payment_case_id\", group_keys=True)[[\"is_payment_true_hit\", \"is_hit_true_hit\"]].apply(\n        lambda row: row\n    )\n    payment_ids = df[\"payment_case_id\"].unique()\n\n    model = Model(solver_name=solver_name)\n\n    # Add the variables\n    x, y, z = define_hit_variables(model, df, ALGORITHMS)\n    alpha = {payment_id: model.add_var(f\"alpha_{payment_id}\", var_type=BINARY) for payment_id in payment_ids}\n\n    # Add constraints\n    objective = []\n    true_positive_constraint = []\n    for payment_id in payment_ids:\n        hit_df = payment_df.loc[payment_id]\n        if hit_df[\"is_payment_true_hit\"].any():\n            true_positive_constraint.append(alpha[payment_id])\n        else:\n            objective.append(alpha[payment_id])\n\n        model += alpha[payment_id] &lt;= xsum(z[hit_id] for hit_id in hit_df.index)\n\n        for hit_id in hit_df.index:\n            model += z[hit_id] &lt;= alpha[payment_id]\n\n            model = define_cutoff_constraints(model, df.loc[hit_id], x, y, z, ALGORITHMS, hit_id)\n\n    model += xsum(true_positive_constraint) &gt;= slack * len(true_positive_constraint)\n    model.objective = minimize(xsum(objective))\n    cutoffs = solve(model, DEFAULT_SEED, x)\n\n    return cutoffs\n</code></pre>"},{"location":"results/","title":"Results","text":""},{"location":"results/#simple-model","title":"Simple model","text":"<p>The solution of the simple models already results in a significant reduction of false positives:</p> Model FP hit reduction [%] FP payment reduction [%] Hit 15.16 9.66 Payment 25.56 17.44 Combined 14.89 9.70 <p>The corresponding cutoffs are:</p> Hit Payment Combined regex_match 91.68 91.68 91.68 jaro_winkler 88.43 93.28 92.97 fuzz_ratio 84.12 94.34 82.25 fuzz_token_sort_ratio 81.20 81.44 81.02 fuzz_partial_token_sort_ratio 97.15 97.67 97.30 fuzz_partial_ratio 97.31 98.97 97.31 <p>Warning</p> <p>The payment-based model results in 66 true positive hits (1.64%) being missed.</p>"},{"location":"results/#relaxed-model","title":"Relaxed model","text":"<p>The false positive hit reduction is quite significant, even when only a small slack is introduced:</p> Slack FP hit reduction [%] FP payment reduction [%] 0.999 15.16 9.66 0.99 25.56 17.44 0.98 14.89 9.70 0.97 14.89 9.70 0.96 14.89 9.70 0.95 14.89 9.70 <p>Graphically, this looks as follows:</p> <p>From this, we can also construct a Pareto curve:</p>"},{"location":"results/#algorithm-combination","title":"Algorithm Combination","text":"<p>For the algorithm combination, we tested out 75 different combinations: the 15 different combinations of algorithms with 5 different weights. The 5 most effective were:</p> Combination FP hit reduction [%] FP payment reduction [%] 0.999 19.23 13.26 0.99 23.76 16.73 0.98 31.29 24.87 0.97 35.81 27.33 0.96 38.18 29.69 0.95 40.68 32.15 <p>The impact of all tested combinations can be seen in the sorted histogram below:</p> <p>It is also interesting to see how the weight impacts the effectiveness of the added algorithm as a function of the weight:</p>"},{"location":"simple-model/","title":"Simple model","text":"<p>At its core, the aim is to shave off false positives while keeping the true positives. There are two flavors of this approach:</p> <ul> <li>Removing false positive hits</li> <li>Removing false positive payments</li> </ul> <p>A payment has one or more hits associated with it, and if at least one hit is a true hit, the payment is considered a true hit.</p>"},{"location":"simple-model/#removing-false-positive-hits","title":"Removing false positive hits","text":"<pre><code>hatch run simple --model_type='hit'\n</code></pre> <p>To identify the optimal cut-off values for removing false positive hits, we formulate the following mathematical optimization problem:</p> \\[ \\begin{array}{llll} \\text{minimize} &amp; \\sum_{h \\in FP} z_h &amp; &amp; \\text{(Minimize false positive hits)} \\\\ \\text{subject to} &amp; z_h = 1 &amp; \\forall h \\in TP &amp; \\text{(Ensure true positive hits)}\\\\ &amp; z_h \\leq \\sum_{a} y_{h, a} &amp; \\forall h &amp; \\text{(If all $y_{h,a}=0$, then $z_h=0$)}\\\\ &amp; y_{h, a} \\leq z_h &amp; \\forall h, a &amp; \\text{(If any $y_{h,a} = 1$, then $z_h = 1$)} \\\\ &amp; s_{h, a} - 100y_{h, a} \\geq x_a - 100 &amp; \\forall h, a &amp; \\text{(If $y_{h,a} = 1$, then $s_{h, a} \\geq x_a$ for a given hit $h$)}\\\\ &amp; s_{h, a} - s_{h, a}y_{h, a} \\leq x_a - \\epsilon &amp; \\forall h, a &amp; \\text{(If $y_{h,a} = 0$, then $s_{h, a} &lt; x_a$)} \\\\ &amp; x_a \\in [80,100] &amp; \\forall a &amp; \\\\ &amp; y_{h, a} \\in \\{0,1\\} &amp; \\forall a,h &amp; \\\\ &amp; z_h \\in \\{0,1\\} &amp; \\forall h &amp; \\\\ \\end{array} \\] <p>where:</p> <ul> <li>\\(x_a\\) is the optimal cut-off for algorithm \\(a\\).</li> <li>\\(y_{h,a}\\) indicates whether algorithm \\(a\\) hits on name \\(h\\).</li> <li>\\(z_h\\) indicates whether name \\(h\\) is a hit or not.</li> <li>\\(FP\\) is the set of false positives hits, i.e. names which are not true hits.</li> <li>\\(TP\\) is the set of true positives hits.</li> <li>\\(s_{h,a}\\) are the scores for algorithm \\(a\\) and name \\(h\\).</li> <li>\\(\\epsilon\\) is the tolerance to make the \"less than\" work mathematically.</li> </ul> <p>Info</p> <p>Theoretically, a lower bound of 0 on the \\(x_a\\) variable would be correct, as one cannot by definition exclude those scores below 80. However, this leads to a tremendous increase in the problem size and therefore, we deemed 80 to be a good threshold. As the Results section shows, none of the optimal cutoffs calculated reach the lower bound of 80.</p>"},{"location":"simple-model/#removing-false-positive-payments","title":"Removing false positive payments","text":"<pre><code>hatch run simple --model_type='payment'\n</code></pre> <p>To identify the optimal cut-off values for removing false positive payments, we formulate the following mathematical optimization problem:</p> \\[ \\begin{array}{llll} \\text{minimize} &amp; \\sum_{p \\in FP} \\alpha_p &amp; &amp; \\text{(Minimize false positive payments)} \\\\ \\text{subject to} &amp; \\sum_{p \\in TP} \\alpha_p = 1 &amp; &amp; \\text{(Ensure true positive payments)}\\\\ &amp; \\alpha_p \\leq \\sum_{h \\in H(p)} z_{h} &amp; \\forall p &amp; \\text{(If all $z_h=0$, then $\\alpha_p=0$)} \\\\ &amp; z_{h} \\leq \\alpha_p &amp; \\forall p, h\\in H(p) &amp; \\text{(If any $z_h=1$, then $\\alpha_p=1$)} \\\\ &amp; z_h \\leq \\sum_{a} y_{h,a} &amp; \\forall h &amp; \\text{(If all $y_{h,a}=0$, then $z_h=0$)}\\\\ &amp; y_{h,a} \\leq z_h &amp; \\forall h, a &amp; \\text{(If any $y_{h,a} = 1$, then $z_h = 1$)} \\\\ &amp; s_{h,a} - 100y_{h,a} \\geq x_a - 100 &amp; \\forall h, a &amp; \\text{(If $y_{h,a} = 1$, then $s_{h,a} \\geq x_a$)}\\\\ &amp; s_{h,a} - s_{h,a}y_{h,a} \\leq x_a - \\epsilon &amp; \\forall h, a &amp; \\text{(If $y_{h,a} = 0$, then $s_{h,a} &lt; x_a$)} \\\\ &amp; x_a \\in [80,100] &amp; \\forall a &amp; \\\\ &amp; y_{h,a} \\in \\{0,1\\} &amp; \\forall a,h &amp; \\\\ &amp; z_h \\in \\{0,1\\} &amp; \\forall h &amp; \\\\ &amp; \\alpha_p \\in \\{0,1\\} &amp; \\forall p &amp; \\\\ \\end{array} \\] <p>where:</p> <ul> <li>\\(x_a\\) is the optimal cut-off for algorithm \\(a\\)</li> <li>\\(y_{h,a}\\) indicates whether algorithm \\(a\\) hits on name \\(h\\)</li> <li>\\(z_h\\) indicates whether name \\(h\\) is a hit or not.</li> <li>\\(FP\\) is the set of false positive payments, i.e. names which are not true hits.</li> <li>\\(TP\\) is the set of true positive payments.</li> <li>\\(H(p)\\) is the set of all hits that are assigned to payment \\(p\\).</li> <li>\\(s_{h,a}\\) are the scores for algorithm \\(a\\) and name \\(h\\).</li> <li>\\(\\epsilon\\) is the tolerance to make the \"less than\" work mathematically.</li> </ul> <p>Note</p> <p>Since we only enforce that we have keep the true positive payments, not the true positive hits, it is possible that solving this model removes true positive hits.</p>"},{"location":"simple-model/#removing-false-positive-payments-while-respecting-true-positive-hits","title":"Removing false positive payments while respecting true positive hits","text":"<pre><code>hatch run simple --model_type='combined'\n</code></pre> <p>To respecte the true positive nature of the hits, we simply have to add this constraint to the payment model:</p> \\[ z_h = 1 &amp; \\forall h \\in TP_{hits} \\] <p>where \\(TP_{hits}\\) is the set of all true positive hits.</p>"},{"location":"simple-model/#implementations","title":"Implementations","text":""},{"location":"simple-model/#opti_fit.models.simple_model.solve_simple_combined_model","title":"<code>solve_simple_combined_model(df, solver_name='CBC', seed=0)</code>","text":"<p>This model combines the hit and payment models such that we should not have any true positive violations while minimizing the true positive payments.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Data with the scores etc.</p> required <code>solver_name</code> <code>str</code> <p>Name of the solver to use</p> <code>'CBC'</code> <code>seed</code> <code>int</code> <p>Random seed for the solver</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The optimal cutoffs</p> Source code in <code>opti_fit/models/simple_model.py</code> <pre><code>def solve_simple_combined_model(df: pd.DataFrame, solver_name: str = \"CBC\", seed: int = 0) -&gt; dict[str, float]:\n    \"\"\"This model combines the hit and payment models such that we should not have any true positive\n    violations while minimizing the true positive payments.\n\n    Args:\n        df (pd.DataFrame): Data with the scores etc.\n        solver_name (str): Name of the solver to use\n        seed (int): Random seed for the solver\n\n    Returns:\n        The optimal cutoffs\n    \"\"\"\n    payment_df = df.groupby(\"payment_case_id\", group_keys=True)[[\"is_payment_true_hit\", \"is_hit_true_hit\"]].apply(\n        lambda row: row\n    )\n    payment_ids = df[\"payment_case_id\"].unique()\n\n    model = Model(solver_name=solver_name)\n\n    # Add the variables\n    x, y, z = define_hit_variables(model, df, ALGORITHMS)\n    alpha = {payment_id: model.add_var(f\"alpha_{payment_id}\", var_type=BINARY) for payment_id in payment_ids}\n\n    # Add constraints\n    objective = []\n    for payment_id in payment_ids:\n        hit_df = payment_df.loc[payment_id]\n        if hit_df[\"is_payment_true_hit\"].any():\n            model += alpha[payment_id] == 1\n        else:\n            objective.append(alpha[payment_id])\n\n        model += alpha[payment_id] &lt;= xsum(z[hit_id] for hit_id in hit_df.index)\n\n        for hit_id, scores in hit_df.iterrows():\n            model += z[hit_id] &lt;= alpha[payment_id]\n            if scores[\"is_hit_true_hit\"]:\n                model += z[hit_id] == 1\n\n            model = define_cutoff_constraints(model, df.loc[hit_id], x, y, z, ALGORITHMS, hit_id)\n\n    model.objective = minimize(xsum(objective))\n    cutoffs = solve(model, seed, x)\n\n    return cutoffs\n</code></pre>"},{"location":"simple-model/#opti_fit.models.simple_model.solve_simple_hit_model","title":"<code>solve_simple_hit_model(df, solver_name='CBC', seed=0)</code>","text":"<p>This is the simplest model for this problem. It tries to minimize the false positive hits while keeping the true positives.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Data with the scores etc.</p> required <code>solver_name</code> <code>str</code> <p>Name of the solver to use</p> <code>'CBC'</code> <code>seed</code> <code>int</code> <p>Random seed for the solver</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The optimal cutoffs</p> Source code in <code>opti_fit/models/simple_model.py</code> <pre><code>def solve_simple_hit_model(df: pd.DataFrame, solver_name: str = \"CBC\", seed: int = 0) -&gt; dict[str, float]:\n    \"\"\"This is the simplest model for this problem. It tries to minimize the false positive hits\n    while keeping the true positives.\n\n    Args:\n        df (pd.DataFrame): Data with the scores etc.\n        solver_name (str): Name of the solver to use\n        seed (int): Random seed for the solver\n\n    Returns:\n        The optimal cutoffs\n    \"\"\"\n    algorithms = [col for col in df.columns if col not in OVERVIEW_COLUMNS]\n\n    model = Model(solver_name=solver_name)\n\n    # Add the variables\n    x, y, z = define_hit_variables(model, df, algorithms)\n\n    # Add constraints\n    objective = []\n    for hit_id, scores in df.iterrows():\n        if scores[\"is_hit_true_hit\"]:\n            model += z[hit_id] == 1\n        else:\n            objective.append(z[hit_id])\n\n        model = define_cutoff_constraints(model, scores, x, y, z, algorithms, hit_id)\n\n    model.objective = minimize(xsum(objective))\n    cutoffs = solve(model, seed, x)\n\n    return cutoffs\n</code></pre>"},{"location":"simple-model/#opti_fit.models.simple_model.solve_simple_payment_model","title":"<code>solve_simple_payment_model(df, solver_name='CBC', seed=0)</code>","text":"<p>This model goes one level up from the simple hit model, as it considers that payments should be true positives, rather than hits.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Data with the scores etc.</p> required <code>solver_name</code> <code>str</code> <p>Name of the solver to use</p> <code>'CBC'</code> <code>seed</code> <code>int</code> <p>Random seed for the solver</p> <code>0</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The optimal cutoffs</p> Source code in <code>opti_fit/models/simple_model.py</code> <pre><code>def solve_simple_payment_model(df: pd.DataFrame, solver_name: str = \"CBC\", seed: int = 0) -&gt; dict[str, float]:\n    \"\"\"This model goes one level up from the simple hit model, as it considers\n    that payments should be true positives, rather than hits.\n\n    Args:\n        df (pd.DataFrame): Data with the scores etc.\n        solver_name (str): Name of the solver to use\n        seed (int): Random seed for the solver\n\n    Returns:\n        The optimal cutoffs\n    \"\"\"\n    payment_df = df.groupby(\"payment_case_id\", group_keys=True)[[\"is_payment_true_hit\", \"is_hit_true_hit\"]].apply(\n        lambda row: row\n    )\n    payment_ids = df[\"payment_case_id\"].unique()\n\n    model = Model(solver_name=solver_name)\n\n    # Add the variables\n    x, y, z = define_hit_variables(model, df, ALGORITHMS)\n    alpha = {payment_id: model.add_var(f\"alpha_{payment_id}\", var_type=BINARY) for payment_id in payment_ids}\n\n    # Add constraints\n    objective = []\n    for payment_id in payment_ids:\n        hit_df = payment_df.loc[payment_id]\n        if hit_df[\"is_payment_true_hit\"].any():\n            model += alpha[payment_id] == 1\n        else:\n            objective.append(alpha[payment_id])\n\n        model += alpha[payment_id] &lt;= xsum(z[hit_id] for hit_id in hit_df.index)\n\n        for hit_id in hit_df.index:\n            model += z[hit_id] &lt;= alpha[payment_id]\n\n            model = define_cutoff_constraints(model, df.loc[hit_id], x, y, z, ALGORITHMS, hit_id)\n\n    model.objective = minimize(xsum(objective))\n    cutoffs = solve(model, seed, x)\n\n    return cutoffs\n</code></pre>"},{"location":"solver-comparisons/","title":"Solver Comparisons","text":"<pre><code>hatch run compare\n</code></pre> <p>We made the choice to use the python-mip library as the modeling framework for this project, as its API is straightforward and it has been around for a few years. This library supports Gurobi, CBC and HiGHS as solvers, and so we naturally were curious how these solvers would compare their behaviour.</p> <p>We would like to express our gratitude to the CBC and HiGHS teams for providing an open-source solver. We also would like to thank Gurobi Optimization for providing an evaluation license in order to run these experiments.</p> <p>Note</p> <p>We needed to use a specific commit, rather than a released version, for the <code>python-mip</code> package, as the HiGHS integration was not released yet when we performed these experiments. Also, <code>python-mip</code> does not allow the specification of the CBC version, which makes this comparison less reproducible.</p>"},{"location":"solver-comparisons/#methodology","title":"Methodology","text":"<p>In order to make the results as robust as possible, we considered the following:</p> <ul> <li>Use a single simple model</li> <li>Use 5 different random seeds</li> </ul>"},{"location":"solver-comparisons/#results","title":"Results","text":"<p>Gurobi is order of magnitudes more performant and efficient than HiGHS and CBC. </p>"},{"location":"the-dataset/","title":"The dataset","text":"<p>The dataset in this repository contains the real algorithm scores from the production environment in Banking Circle. The set is a compressed csv file, where each row represents one hit. The dataset has the following columns:</p> <ul> <li>payment_case_id: A unique identifier for each payment</li> <li>is_payment_true_hit: Whether the payment is a true hit or not</li> <li>is_hit_true_hit: Whether the hit is a true hit or not</li> <li>regex_match: Score of this hit for the algorithm REGEX_MATCH</li> <li>jaro_winkler: Score of this hit for the algorithm JARO_WINKLER</li> <li>fuzz_ratio: Score of this hit for the algorithm FUZZ_RATIO</li> <li>fuzz_partial_ratio: Score of this hit for the algorithm FUZZ_PARTIAL_RATIO</li> <li>fuzz_token_sort_ratio: Score of this hit for the algorithm FUZZ_TOKEN_SORT_RATIO</li> <li>fuzz_partial_token_sort_ratio: Score of this hit for the algorithm FUZZ_PARTIAL_TOKEN_SORT_RATIO</li> </ul> <p>Note</p> <p>In the <code>read_dataset</code> function of the code, we round the scores to the second digits to reduce numerical issues. Especially since we are looking to calculate cutoffs, having 13 digits after the decimal will not be helpful.</p>"},{"location":"the-dataset/#the-dataset-in-numbers","title":"The dataset in numbers","text":"<ul> <li>853049 total hits, of which 4023 are true positive hits (0.47%)</li> <li>379691 total payments, of which 2572 are true positives (0.68%)</li> </ul>"},{"location":"the-dataset/#hit-distribution","title":"Hit distribution","text":"<p>On average, a payment that is a true hit has 3.87 hits associated with it, while a false positive only has 2.23. However, the distributions look remarkably similar:</p> <p>This suggests that while there may be information to be gained from the number of hits for a given payment, it is not a clear avenue to pursue.</p>"}]}